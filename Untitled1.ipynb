{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tensorflow as tf\n",
      "with tf.device('/cpu:0'):\n",
      "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
      "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
      "c = tf.matmul(a, b)\n",
      "# Creates a session with log_device_placement set to True.\n",
      "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
      "# Runs the op.\n",
      "print sess.run(c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 22.  28.]\n",
        " [ 49.  64.]]\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2  \n",
      "import numpy as np  \n",
      "import tensorflow as tf\n",
      "image_path = './'  \n",
      "list_file  = 'list.txt'  \n",
      "height = 10\n",
      "width = 10\n",
      "  \n",
      "image_name_list = [] # read image  \n",
      "with open(image_path + list_file) as fid:  \n",
      "    image_name_list = [x.strip() for x in fid.readlines()]  \n",
      "image_num = len(image_name_list)  \n",
      "  \n",
      "data = np.zeros((image_num, height, width, 3), np.uint8)  \n",
      "  \n",
      "for idx in range(image_num):  \n",
      "    img = cv2.imread(image_name_list[idx])  \n",
      "    img = cv2.resize(img, (height, width))  \n",
      "    data[idx, :, :, :] = img  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: './list.txt'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-14-621061843bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mimage_name_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# read image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mimage_name_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mimage_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './list.txt'"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2  \n",
      "import numpy as np  \n",
      "  \n",
      "image_path = '/home/lenovo3/'  \n",
      "list_file  = 'list.txt'  \n",
      "height = 48  \n",
      "width = 48  \n",
      "  \n",
      "image_name_list = ['2.jpg'] # read image  \n",
      "with open('list.txt') as fid:  \n",
      "    image_name_list = [x.strip() for x in fid.readlines()]  \n",
      "image_num = len(image_name_list)  \n",
      "  \n",
      "data = np.zeros((image_num, height, width, 3), np.uint8)  \n",
      "  \n",
      "for idx in range(image_num):  \n",
      "    img = cv2.imread(image_name_list[idx])  \n",
      "    img = cv2.resize(img, (height, width))  \n",
      "    data[idx, :, :, :] = img  \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: 'list.txt'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-18-09302632a11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mimage_name_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'2.jpg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# read image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'list.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mimage_name_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mimage_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'list.txt'"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import cv2\n",
      "import tensorflow as tf\n",
      "frameSize = (0,0); \n",
      "frameCount = 0;\n",
      "x = tf.placeholder(tf.float32, [frameCount, frameSize[0] * frameSize[1] * 3])\n",
      "W = tf.Variable(tf.zeros([frameSize[0]*frameSize[1]*3, frameCount]))\n",
      "b = tf.Variable(tf.zeros([frameCount]))\n",
      "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
      "y_ = tf.placeholder(\"float\", [None,frameCount])\n",
      "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
      "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
      "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
      "init = tf.initialize_all_variables()\n",
      "sess = tf.Session()\n",
      "sess.run(init)\n",
      "for i in range(1000):\n",
      "    batch_xs, batch_ys = samples, responses\n",
      "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
      "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
      "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
      "print sess.run(accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[21.0, 7.0]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import cv2\n",
      "import sys\n",
      "import math\n",
      "import pickle\n",
      "import tensorflow as tf\n",
      "def GetVideoProperties(filePath):\n",
      "    inputVideo = cv2.VideoCapture(filePath);\n",
      "    fileName = filePath\n",
      "    if inputVideo.isOpened() == None:\n",
      "        return False;\n",
      "    frameCount = 0;\n",
      "    while inputVideo.isOpened():\n",
      "        ret, frame = inputVideo.read()\n",
      "        if ret == False:\n",
      "            break;\n",
      "        if frame is None:\n",
      "            return False;\n",
      "        if frame.shape[2] != 3:\n",
      "            return False;\n",
      "        frameSize = (int(inputVideo.get(cv2.CAP_PROP_FRAME_WIDTH)), int(inputVideo.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
      "        frameCount += 1;\n",
      "    fps = inputVideo.get(cv2.CAP_PROP_FPS)\n",
      "    return [fps, frameSize, frameCount]\n",
      "\n",
      "def NumToNNValuesSimple(num, maxValue):\n",
      "    res = np.zeros((maxValue, 1))\n",
      "    res[num, 0]= 1.0\n",
      "    res = res.flatten()\n",
      "    return res\n",
      "\n",
      "def ImageToNNValues(img):\n",
      "    #print img\n",
      "    result = img.flatten()\n",
      "    result = result / 256.0\n",
      "    return result\n",
      "\n",
      "def NNValuesToImage(values, frameSize):\n",
      "    values *= 256.0\n",
      "    result = values.reshape(frameSize[0], frameSize[1], 3)\n",
      "    return result\n",
      "\n",
      "def ReconstructFrame(nnoutput, frameSize, frameNum, frameCount, NumToNNValuesSimple):\n",
      "    frame = NNValuesToImage(nnoutput, frameSize)\n",
      "    return frame\n",
      "\n",
      "def ReconstructMovie(nnoutput, frameSize, frameCount, fps, filePath, NumToNNValuesSimple):\n",
      "    \n",
      "    print \"Loading neural network\"\n",
      "    if nnoutput is None:\n",
      "        return False\n",
      "    fourcc = cv2.VideoWriter_fourcc(*'XVID');\n",
      "    outputVideo = cv2.VideoWriter(filePath, fourcc, fps, frameSize);\n",
      "    if outputVideo.isOpened() == None:\n",
      "        print \"Could not open the output video for write: \", filePath\n",
      "        return False;\n",
      "    for frameNum in range(frameCount):\n",
      "        if  frameNum == 0 or frameNum == frameCount - 1 or frameNum % 100 == 0:\n",
      "            print \"Reconstructing frame \", frameNum + 1, \" of \", frameCount\n",
      "        frame = ReconstructFrame(nnoutput[frameNum], frameSize, frameNum, frameCount, NumToNNValuesSimple)\n",
      "        #norm = np.linalg.norm(frame)\n",
      "        #frame = frame / norm\n",
      "        #print frame\n",
      "        #frame = frame * 256.0\n",
      "        frame = frame.astype('u1')\n",
      "        \n",
      "        #print len(frame), len(frame[0]), len(frame[0][0])\n",
      "        cv2.imshow('frame',frame)\n",
      "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "            break\n",
      "        outputVideo.write(frame);\n",
      "    print \"Saved \", filePath\n",
      "    return True\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    inFilePath = \"/home/lenovo3/3/box1.avi\"\n",
      "\n",
      "    nnFilePath = inFilePath + \".nncv\";\n",
      "    outFilePath = inFilePath + \".n_n.avi\";\n",
      "    maxIters = 1000;\n",
      "    epsilon = 0.00000000001;\n",
      "\n",
      "    [fps, frameSize, frameCount] = GetVideoProperties(inFilePath)\n",
      "    \n",
      "    print inFilePath, \" - fps: \", fps, \" - frameSize: \", frameSize, \" - frameCount: \", frameCount\n",
      "\n",
      "    layerSizes = [];\n",
      "    \n",
      "    inputLayerSize = NumToNNValuesSimple(0, frameCount).shape[0];\n",
      "    outputLayerSize = frameSize[0] * frameSize[1] * 3;\n",
      "    hiddenLayerSize = int(math.sqrt(frameCount)) + 1;\n",
      "    layerSizes.append(inputLayerSize );\n",
      "    layerSizes.append(hiddenLayerSize );\n",
      "    layerSizes.append(hiddenLayerSize );\n",
      "    layerSizes.append(outputLayerSize );\n",
      "    layerSizes = np.array(layerSizes)\n",
      "    \n",
      "    nnPtr = cv2.ml.ANN_MLP_create();\n",
      "    nnPtr.setBackpropMomentumScale(0.0)\n",
      "    nnPtr.setBackpropWeightScale(0.001)\n",
      "    nnPtr.setLayerSizes( layerSizes );\n",
      "    nnPtr.setActivationFunction(cv2.ml.ANN_MLP_GAUSSIAN, 2, 1);\n",
      "    nnPtr.setTrainMethod( cv2.ml.ANN_MLP_RPROP, 0.1, sys.float_info.epsilon)\n",
      "    nnPtr.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, maxIters, epsilon));\n",
      "\n",
      "    samples = np.empty((frameCount, inputLayerSize))\n",
      "    responses = np.empty((frameCount, outputLayerSize))\n",
      "\n",
      "    inputVideo = cv2.VideoCapture(inFilePath) ;\n",
      "    fileName = inFilePath;\n",
      "\n",
      "    for frameNum in range(frameCount):\n",
      "        if frameNum == 0 or frameNum == frameCount - 1 or frameNum % 100 == 0:\n",
      "            print \"Loading frame \", frameNum + 1, \" of \", frameCount\n",
      "        ret, frame = inputVideo.read()\n",
      "        if ret == False:\n",
      "            break;\n",
      "        if frame is None:\n",
      "            print 1;\n",
      "        imageNNValues = ImageToNNValues(frame);\n",
      "        frameNumNNValues = NumToNNValuesSimple(frameNum, frameCount);\n",
      "        #print len(samples), len(samples[0]), len(responses), len(responses[0])\n",
      "        np.copyto(samples[frameNum], frameNumNNValues);\n",
      "        np.copyto(responses[frameNum], imageNNValues);\n",
      "    print samples.shape, responses.shape\n",
      "    x = tf.placeholder(tf.float32, [None, frameCount])\n",
      "    W = tf.Variable(tf.zeros([frameCount, frameSize[0]*frameSize[1]*3]))\n",
      "    b = tf.Variable(tf.zeros([frameSize[0] * frameSize[1] * 3]))\n",
      "    print tf.shape(x), tf.shape(W), tf.shape(b)\n",
      "    y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
      "    y_ = tf.placeholder(\"float\", [None,frameSize[0] * frameSize[1] * 3])\n",
      "    cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
      "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
      "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
      "    init = tf.initialize_all_variables()\n",
      "    sess = tf.Session()\n",
      "    sess.run(init)\n",
      "    \n",
      "    saver = tf.train.Saver()\n",
      "    \n",
      "    print y_\n",
      "    for i in range(3000):\n",
      "        if i % 100 == 0:\n",
      "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
      "            print sess.run(accuracy, feed_dict={x: batch_xs, y_: batch_ys})\n",
      "        batch_xs, batch_ys = samples, responses\n",
      "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
      "        save_path = saver.save(sess, \"/home/lenovo3/saved_model.txt\")\n",
      "    \n",
      "    nnoutput = sess.run(y, feed_dict={x: batch_xs})\n",
      "    #print \"Training neural network\"\n",
      "    #nnPtr.train(samples, cv2.ml.ROW_SAMPLE, responses);\n",
      "    #print len(samples)\n",
      "    #print \"Saving neural network\"\n",
      "    #nnPtr.save(nnFilePath);\n",
      "    #print nnPtr\n",
      "    ReconstructMovie(nnoutput, frameSize, frameCount, fps, outFilePath, NumToNNValuesSimple);\n",
      "    inputVideo.release()\n",
      "    outputVideo.release()\n",
      "    cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/lenovo3/3/box1.avi  - fps:  25.0  - frameSize:  (30, 30)  - frameCount:  96\n",
        "Loading frame  1  of  96\n",
        "Loading frame  96  of  96\n",
        "(96, 96) (96, 2700)\n",
        "Tensor(\"Shape_3:0\", shape=(2,), dtype=int32) Tensor(\"Shape_4:0\", shape=(2,), dtype=int32) Tensor(\"Shape_5:0\", shape=(1,), dtype=int32)\n",
        "Tensor(\"Placeholder_3:0\", shape=(?, 2700), dtype=float32)"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'batch_xs' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-81917fe4e8ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mprint\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'batch_xs' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "import numpy as np\n",
      "a = np.array([2], dtype = \"u1\")\n",
      "v = np.linalg.norm(a)\n",
      "a/v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "array([ 1.])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import cv2\n",
      "\n",
      "cap = cv2.VideoCapture(0)\n",
      "\n",
      "# Define the codec and create VideoWriter object\n",
      "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
      "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
      "\n",
      "while(cap.isOpened()):\n",
      "    ret, frame = cap.read()\n",
      "    if ret==True:\n",
      "        #frame = cv2.flip(frame,0)\n",
      "\n",
      "        # write the flipped frame\n",
      "        out.write(frame)\n",
      "\n",
      "        cv2.imshow('frame',frame)\n",
      "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "            break\n",
      "    else:\n",
      "        break\n",
      "\n",
      "# Release everything if job is finished\n",
      "cap.release()\n",
      "out.release()\n",
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}